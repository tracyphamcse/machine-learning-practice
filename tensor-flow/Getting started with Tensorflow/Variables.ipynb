{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\n",
    "\n",
    "> Variables are manipulated via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Unlike tf.Tensor objects, a tf.Variable exists outside the context of a single session.run call.\n",
    "\n",
    "> Internally, a tf.Variable stores a persistent tensor. Specific ops allow you to read and modify the values of this tensor. These modifications are visible across multiple tf.Sessions, so multiple workers can see the same values for a tf.Variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating variable\n",
    "\n",
    ">The best way to create a variable is to call the tf.get_variable function. This function requires you to specify the Variable's name. This name will be used by other replicas to access the same variable, as well as to name this variable's value when checkpointing and exporting models. tf.get_variable also allows you to reuse a previously created variable of the same name, making it easy to define models which reuse layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x1165917d0>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x116591810>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x1165de1d0>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Creates a variable named \"my_variable\" which is a three-dimensional tensor with shape [1, 2, 3].\n",
    "    This variable will, by default, have the dtype tf.float32 and \n",
    "    its initial value will be randomized via tf.glorot_uniform_initializer.\n",
    "'''\n",
    "\n",
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
    "print my_variable\n",
    "\n",
    "\n",
    "'''\n",
    "    Can change the dtype and initializer of the variable\n",
    "    \n",
    "    Initializer can be a tf.Tensor, \n",
    "    you should not specify the variable's shape, as the shape of the initializer tensor will be used.\n",
    "'''\n",
    "my_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32, initializer=tf.zeros_initializer)\n",
    "print my_int_variable\n",
    "\n",
    "\n",
    "other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32, initializer=tf.constant([23, 42]))\n",
    "print other_variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable my_variable already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n",
      "\n",
      "  File \"<ipython-input-7-ecad63f6590a>\", line 7, in <module>\n",
      "    my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
      "  File \"/Users/tranpham/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/Users/tranpham/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "\n",
      "\n",
      "<tensorflow.python.ops.variables.Variable object at 0x116591190>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    It will raise an error if you create the same-name variable\n",
    "'''\n",
    "\n",
    "try:\n",
    "    my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
    "except Exception, e:\n",
    "    print e\n",
    "    print\n",
    "\n",
    "'''\n",
    "    Use tf.reset_default_graph to reset all declared variable, graph, ... \n",
    "'''\n",
    "tf.reset_default_graph()\n",
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
    "print my_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable collections\n",
    "\n",
    "> **tf.GraphKeys.GLOBAL_VARIABLES** --- variables that can be shared across multiple devices, *\n",
    "\n",
    "> **tf.GraphKeys.TRAINABLE_VARIABLES** --- variables for which TensorFlow will calculate gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x1165478d0>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x1165475d0>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    2 ways to create the variable that is not trainable:\n",
    "        - put to the LOCAL_VARIABLES collection\n",
    "        - or set trainable = False\n",
    "'''\n",
    "\n",
    "my_local = tf.get_variable(\"my_local\", shape=(), collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
    "print my_local\n",
    "\n",
    "my_non_trainable = tf.get_variable(\"my_non_trainable\", shape=(), trainable=False)\n",
    "print my_non_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Make a new collection and add the variable to that collection\n",
    "'''\n",
    "\n",
    "tf.add_to_collection(\"my_collection_name\", my_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.ops.variables.Variable object at 0x1165478d0>]\n",
      "[<tensorflow.python.ops.variables.Variable object at 0x116591190>, <tensorflow.python.ops.variables.Variable object at 0x1165478d0>]\n",
      "[<tensorflow.python.ops.variables.Variable object at 0x1165478d0>]\n",
      "\n",
      "type object 'GraphKeys' has no attribute 'GLOBAL_VARIABLES'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    View the list of variables in each collection\n",
    "'''\n",
    "\n",
    "print tf.get_collection(\"my_collection_name\")\n",
    "print tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "print tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)\n",
    "print\n",
    "\n",
    "'''\n",
    "    GOBAL_VARIABLES seems not in this tensorflow version. Some raise that they got this issue with v11 too. \n",
    "'''\n",
    "try: \n",
    "    print tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "except Exception, e:\n",
    "    print e\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devices\n",
    "\n",
    "The variable can also be put on the particular device\n",
    "\n",
    "> It is particularly important for variables to be in the correct device in distributed settings. Accidentally putting variables on workers instead of parameter servers, for example, can severely slow down training or, in the worst case, let each worker blithely forge ahead with its own independent copy of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:1\"):\n",
    "    v = tf.get_variable(\"v\", [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_spec = {\n",
    "    \"ps\": [\"ps0:2222\", \"ps1:2222\"],\n",
    "    \"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]}\n",
    "\n",
    "\n",
    "'''\n",
    "     Use tf.train.replica_device_setter to automatically place variables in parameter servers\n",
    "'''\n",
    "with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n",
    "    v2 = tf.get_variable(\"v2\", shape=[20, 20])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variable \n",
    "\n",
    "> Before you can use a variable, it must be initialized. If you are programming in the low-level TensorFlow API (that is, you are explicitly creating your own graphs and sessions), you must explicitly initialize the variables. Most high-level frameworks such as tf.contrib.slim, tf.estimator.Estimator and Keras automatically initialize variables for you before training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    TensorFlow document introduces the \"tf.global_variables_initializer()\" method to initialize all global variables\n",
    "    however, that method is not available in my tensorflow version\n",
    "    \n",
    "    After getting the initializer, use session.run() to initialize the variables\n",
    "'''\n",
    "\n",
    "all_variables_initializer = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "'''\n",
    "    get many issues with the current tensorflow version\n",
    "    the below initializer methods also raise argument error\n",
    "     \n",
    "    v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "    w = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    To assign a value to a variable, use the methods assign, assign_add, and friends in the tf.Variable class. \n",
    "    For example, here is how you can call these methods:\n",
    "'''\n",
    "\n",
    "v = tf.get_variable(\"v4\", shape=())\n",
    "assignment = v.assign_add(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing variables / Variable scopes\n",
    "\n",
    "> Allow you to control variable reuse when calling functions which implicitly create and use variables\n",
    "\n",
    "> Allow you to name your variables in a hierarchical and understandable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n",
      "\n",
      "  File \"<ipython-input-38-a16efc968852>\", line 4, in conv_relu\n",
      "    initializer=tf.random_normal_initializer())\n",
      "  File \"<ipython-input-39-199793ada2fc>\", line 3, in <module>\n",
      "    x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
      "  File \"/Users/tranpham/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Cannot call the conv_relu again because \"weights\" and \"biases\" were defined\n",
    "'''\n",
    "\n",
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
    "\n",
    "try:\n",
    "    x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails.\n",
    "except Exception, e:\n",
    "    print e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2/Relu:0' shape=(1, 10, 10, 32) dtype=float32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Use variable_scope to create new variable (with new name)\n",
    "'''\n",
    "\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])\n",
    "\n",
    "my_image_filter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    2 ways to use resued to share the variable\n",
    "'''\n",
    "\n",
    "with tf.variable_scope(\"model2\"):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model2\", reuse=True):\n",
    "    output2 = my_image_filter(input2)\n",
    "        \n",
    "        \n",
    "with tf.variable_scope(\"model3\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "    scope.reuse_variables()\n",
    "    output2 = my_image_filter(input2)\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "   For the #1 way, beside using the \"model\" string name, you can also define the scope and reuse that scope \n",
    "'''\n",
    "with tf.variable_scope(\"model4\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(scope, reuse=True):\n",
    "    output2 = my_image_filter(input2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
